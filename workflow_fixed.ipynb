{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé§ IntervuAgent - LangGraph Interview Workflow\n",
    "\n",
    "This notebook lets you **build, visualize, and test** the interview workflow step-by-step before integrating it into the app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define State & Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterviewState(BaseModel):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "    student_name: str | None = None\n",
    "    selected_topic: str | None = None\n",
    "\n",
    "    stage: Literal[\n",
    "        \"ask_name\",\n",
    "        \"extract_name\",\n",
    "        \"ask_topic\",\n",
    "        \"extract_topic\",\n",
    "        \"ask_question\",\n",
    "        \"await_answer\",\n",
    "        \"end\"\n",
    "    ] = \"ask_name\"\n",
    "\n",
    "    question_count: int = 0\n",
    "    max_questions: int = 3\n",
    "\n",
    "    intent: Literal[\"continue\", \"quit\"] = \"continue\"\n",
    "    should_end: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameExtraction(BaseModel):\n",
    "    name: str\n",
    "\n",
    "class TopicExtraction(BaseModel):\n",
    "    topic: str\n",
    "\n",
    "class EvalIntentOutput(BaseModel):\n",
    "    feedback: str\n",
    "    intent: Literal[\"continue\", \"quit\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Main LLM for questions and evaluation\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.4,\n",
    "    max_output_tokens=1024,\n",
    ")\n",
    "\n",
    "# Fast LLM for simple extractions (name, topic) - lower tokens = faster\n",
    "llm_fast = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.0,\n",
    "    max_output_tokens=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_by_stage(state: InterviewState):\n",
    "    return state.stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Graph Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_name_node(state: InterviewState):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            AIMessage(content=\"Hey there! üëã I'm your friendly AI interviewer. Before we start, what's your name?\")\n",
    "        ],\n",
    "        \"stage\": \"extract_name\"\n",
    "    }\n",
    "\n",
    "def extract_name_node(state: InterviewState):\n",
    "    structured_llm = llm_fast.with_structured_output(NameExtraction)\n",
    "    last_user_msg = state.messages[-1].content\n",
    "    result = structured_llm.invoke([\n",
    "        SystemMessage(content=\"Extract only the first name from the user message. Return JSON.\"),\n",
    "        HumanMessage(content=last_user_msg)\n",
    "    ])\n",
    "    return {\n",
    "        \"student_name\": result.name,\n",
    "        \"stage\": \"ask_topic\"\n",
    "    }\n",
    "\n",
    "def ask_topic_node(state: InterviewState):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            AIMessage(content=f\"Awesome, {state.student_name}! üéØ What topic would you like to practice? \"\n",
    "                             f\"(e.g. Python, JavaScript, SQL, React, Java, C++, etc.)\")\n",
    "        ],\n",
    "        \"stage\": \"extract_topic\"\n",
    "    }\n",
    "\n",
    "def extract_topic_node(state: InterviewState):\n",
    "    structured_llm = llm_fast.with_structured_output(TopicExtraction)\n",
    "    last_user_msg = state.messages[-1].content\n",
    "    result = structured_llm.invoke([\n",
    "        SystemMessage(content=\"Extract only the technical topic name. Return JSON.\"),\n",
    "        HumanMessage(content=last_user_msg)\n",
    "    ])\n",
    "    return {\n",
    "        \"selected_topic\": result.topic,\n",
    "        \"stage\": \"ask_question\"\n",
    "    }\n",
    "\n",
    "def ask_question_node(state: InterviewState):\n",
    "    # Only send the last 4 messages for context (faster, saves tokens)\n",
    "    recent_msgs = state.messages[-4:] if len(state.messages) > 4 else state.messages\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=f\"\"\"You are a friendly, encouraging technical interviewer talking to a BEGINNER.\n",
    "The student's name is {state.student_name} and the topic is {state.selected_topic}.\n",
    "\n",
    "Rules:\n",
    "- Ask ONE simple, beginner-level question.\n",
    "- Think 'first week of learning' level - basic concepts, definitions, simple use cases.\n",
    "- Maximum 2 sentences.\n",
    "- Do NOT ask tricky or advanced questions.\n",
    "- Sound warm and human, like a supportive mentor.\n",
    "- Do NOT repeat a question already asked.\n",
    "- Do NOT explain the answer.\"\"\")\n",
    "    ]\n",
    "    messages.extend(recent_msgs)\n",
    "    messages.append(\n",
    "        HumanMessage(content=f\"Ask a beginner-level question about {state.selected_topic}. Question #{state.question_count + 1}\")\n",
    "    )\n",
    "    response = llm.invoke(messages)\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=response.content)],\n",
    "        \"stage\": \"await_answer\"\n",
    "    }\n",
    "\n",
    "def evaluate_and_check_node(state: InterviewState):\n",
    "    structured_llm = llm.with_structured_output(EvalIntentOutput)\n",
    "    last_user_msg = state.messages[-1].content\n",
    "\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            result = structured_llm.invoke([\n",
    "                SystemMessage(content=\"\"\"You are a warm, encouraging interviewer giving feedback to a BEGINNER.\n",
    "\n",
    "1. Give short, friendly feedback (2-3 sentences max). Be encouraging!\n",
    "2. If the answer is wrong, gently correct them without being harsh.\n",
    "3. If the student says anything like 'stop', 'quit', 'exit', 'end', 'done',\n",
    "   'no more', 'that is enough', 'I want to stop', or similar, set intent to 'quit'.\n",
    "4. Otherwise set intent to 'continue'.\n",
    "\n",
    "Return valid JSON only. No markdown wrapping.\"\"\"),\n",
    "                HumanMessage(content=last_user_msg)\n",
    "            ])\n",
    "            break\n",
    "        except Exception:\n",
    "            if attempt == 2:\n",
    "                result = EvalIntentOutput(feedback=\"Nice effort! Let's keep going.\", intent=\"continue\")\n",
    "            continue\n",
    "\n",
    "    new_count = state.question_count + 1\n",
    "    should_continue = result.intent == \"continue\" and new_count < state.max_questions\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=result.feedback)],\n",
    "        \"intent\": result.intent,\n",
    "        \"question_count\": new_count,\n",
    "        \"stage\": \"ask_question\" if should_continue else \"end\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_node(state: InterviewState):\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"Great job {state.student_name}! üéâ That was a solid practice session on {state.selected_topic}. Keep learning and you'll do amazing. Good luck! üöÄ\")],\n",
    "        \"should_end\": True\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build the Graph\n",
    "\n",
    "### ‚ö° Key design: `interrupt_before` pauses for user input\n",
    "\n",
    "The graph pauses **before** `extract_name`, `extract_topic`, and `evaluate_answer` nodes.  \n",
    "Your code collects user input, injects it via `graph.update_state()`, and resumes with `graph.invoke(None)`.  \n",
    "This avoids redundant LLM calls ‚Äî the graph only runs when it has real input to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(InterviewState)\n",
    "\n",
    "workflow.add_node(\"ask_name\", ask_name_node)\n",
    "workflow.add_node(\"extract_name\", extract_name_node)\n",
    "workflow.add_node(\"ask_topic\", ask_topic_node)\n",
    "workflow.add_node(\"extract_topic\", extract_topic_node)\n",
    "workflow.add_node(\"ask_question\", ask_question_node)\n",
    "workflow.add_node(\"evaluate_answer\", evaluate_and_check_node)\n",
    "workflow.add_node(\"end\", end_node)\n",
    "\n",
    "workflow.set_entry_point(\"ask_name\")\n",
    "\n",
    "workflow.add_conditional_edges(\"ask_name\", route_by_stage, {\"extract_name\": \"extract_name\"})\n",
    "workflow.add_conditional_edges(\"extract_name\", route_by_stage, {\"ask_topic\": \"ask_topic\"})\n",
    "workflow.add_conditional_edges(\"ask_topic\", route_by_stage, {\"extract_topic\": \"extract_topic\"})\n",
    "workflow.add_conditional_edges(\"extract_topic\", route_by_stage, {\"ask_question\": \"ask_question\"})\n",
    "workflow.add_conditional_edges(\"ask_question\", route_by_stage, {\"await_answer\": \"evaluate_answer\"})\n",
    "workflow.add_conditional_edges(\"evaluate_answer\", route_by_stage, {\n",
    "    \"ask_question\": \"ask_question\",\n",
    "    \"end\": \"end\"\n",
    "})\n",
    "\n",
    "workflow.add_edge(\"end\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = workflow.compile(\n",
    "    checkpointer=memory,\n",
    "    interrupt_before=[\"extract_name\", \"extract_topic\", \"evaluate_answer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```mermaid\n",
       "---\n",
       "config:\n",
       "  flowchart:\n",
       "    curve: linear\n",
       "---\n",
       "graph TD;\n",
       "\t__start__([<p>__start__</p>]):::first\n",
       "\task_name(ask_name)\n",
       "\textract_name(extract_name<hr/><small><em>__interrupt = before</em></small>)\n",
       "\task_topic(ask_topic)\n",
       "\textract_topic(extract_topic<hr/><small><em>__interrupt = before</em></small>)\n",
       "\task_question(ask_question)\n",
       "\tevaluate_answer(evaluate_answer<hr/><small><em>__interrupt = before</em></small>)\n",
       "\tend(end)\n",
       "\t__end__([<p>__end__</p>]):::last\n",
       "\t__start__ --> ask_name;\n",
       "\task_name -.-> extract_name;\n",
       "\task_question -. &nbsp;await_answer&nbsp; .-> evaluate_answer;\n",
       "\task_topic -.-> extract_topic;\n",
       "\tevaluate_answer -.-> ask_question;\n",
       "\tevaluate_answer -.-> end;\n",
       "\textract_name -.-> ask_topic;\n",
       "\textract_topic -.-> ask_question;\n",
       "\tend --> __end__;\n",
       "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
       "\tclassDef first fill-opacity:0\n",
       "\tclassDef last fill:#bfb6fc\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython.display as display\n",
    "\n",
    "mermaid_code = graph.get_graph().draw_mermaid()\n",
    "display.Markdown(f\"```mermaid\\n{mermaid_code}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run the Interview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ AI: Hey there! üëã I'm your friendly AI interviewer. Before we start, what's your name?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üë§ You: hi my name is jayanth\n",
      "\n",
      "‚è≥ Thinking...\n",
      "\n",
      "ü§ñ AI: Awesome, jayanth! üéØ What topic would you like to practice? (e.g. Python, JavaScript, SQL, React, Java, C++, etc.)\n",
      "\n",
      "\n",
      "üë§ You: sql please\n",
      "\n",
      "‚è≥ Thinking...\n",
      "\n",
      "ü§ñ AI: Great choice, jayanth! SQL is super useful.\n",
      "\n",
      "To kick things off, in your own words, what would you say SQL is primarily used for? No need for a perfect definition, just your understanding!\n",
      "\n",
      "\n",
      "üë§ You: sql is an language to create, manage the databse systems , it has DML, DQL,TCL, DRL\n",
      "\n",
      "‚è≥ Thinking...\n",
      "\n",
      "ü§ñ AI: That's a great start! You're absolutely right that SQL is used for creating and managing databases. You've correctly identified DML, DQL, and TCL. We also have DDL for defining the database structure and DCL for controlling access, and DRL is often grouped under DQL.\n",
      "\n",
      "ü§ñ AI: Excellent, jayanth! You've got a good handle on the different categories of SQL commands.\n",
      "\n",
      "Let's move on to one of the most common commands. What do you think the `SELECT` statement is used for in SQL?\n",
      "\n",
      "\n",
      "üë§ You: SELECT is used to retrive data from the table\n",
      "\n",
      "‚è≥ Thinking...\n",
      "\n",
      "ü§ñ AI: That's absolutely right! You've got a great understanding of what SELECT does. Keep up the fantastic work!\n",
      "\n",
      "ü§ñ AI: Excellent, jayanth! You're doing great.\n",
      "\n",
      "You mentioned `SELECT` is used to retrieve data. When you're writing a `SELECT` statement, you also need to tell SQL *which* table to get the data from. Which keyword do we use for that?\n",
      "\n",
      "\n",
      "üë§ You: we use SELECT column_name from TABLE_NAME\n",
      "\n",
      "‚è≥ Thinking...\n",
      "\n",
      "ü§ñ AI: That's absolutely right! You've got the basic SELECT statement down perfectly for picking out a specific column. Great job!\n",
      "\n",
      "ü§ñ AI: Great job jayanth! üéâ That was a solid practice session on sql. Keep learning and you'll do amazing. Good luck! üöÄ\n",
      "\n",
      "\n",
      "‚úÖ Interview complete!\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "# Auto-generate a unique session ID each run\n",
    "config = {\"configurable\": {\"thread_id\": f\"interview-{uuid.uuid4().hex[:8]}\"}}\n",
    "\n",
    "# STEP 1: Start the graph\n",
    "graph.invoke({\"messages\": []}, config=config)\n",
    "\n",
    "# Track how many messages we've already displayed\n",
    "state = graph.get_state(config)\n",
    "all_msgs = state.values.get(\"messages\", [])\n",
    "displayed_count = 0\n",
    "\n",
    "# Print AI greeting\n",
    "for msg in all_msgs:\n",
    "    if isinstance(msg, AIMessage):\n",
    "        print(f\"\\nü§ñ AI: {msg.content}\\n\")\n",
    "displayed_count = len(all_msgs)\n",
    "\n",
    "# STEP 2: Main loop\n",
    "while True:\n",
    "    # Check if graph has finished (no more nodes to run)\n",
    "    if not graph.get_state(config).next:\n",
    "        print(\"\\n‚úÖ Interview complete!\")\n",
    "        break\n",
    "\n",
    "    user_input = input(\"üë§ You: \").strip()\n",
    "    if not user_input:\n",
    "        continue\n",
    "\n",
    "    # Manual quit keywords (instant exit, no LLM call)\n",
    "    if user_input.lower() in (\"quit\", \"exit\", \"stop\", \"end\", \"bye\", \"done\"):\n",
    "        print(\"\\nüëã Interview ended. Thanks for practicing!\")\n",
    "        break\n",
    "\n",
    "    print(f\"\\nüë§ You: {user_input}\\n\")\n",
    "    print(\"‚è≥ Thinking...\\n\")\n",
    "\n",
    "    # Resume graph with user input\n",
    "    graph.update_state(config, {\"messages\": [HumanMessage(content=user_input)]})\n",
    "    graph.invoke(None, config=config)\n",
    "\n",
    "    # Print ALL new AI messages (feedback + next question)\n",
    "    state = graph.get_state(config)\n",
    "    all_msgs = state.values.get(\"messages\", [])\n",
    "    new_msgs = all_msgs[displayed_count:]\n",
    "\n",
    "    for msg in new_msgs:\n",
    "        if isinstance(msg, AIMessage):\n",
    "            print(f\"ü§ñ AI: {msg.content}\\n\")\n",
    "\n",
    "    displayed_count = len(all_msgs)\n",
    "\n",
    "    # Check if interview ended naturally (max questions or user said quit in answer)\n",
    "    if state.values.get(\"should_end\", False):\n",
    "        print(\"\\n‚úÖ Interview complete!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Debug: Inspect Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "{'content': \"Hey there! üëã I'm your friendly AI interviewer. Before we start, what's your name?\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': '49639bd7-f2bc-452f-8f9f-fa5fd66de351', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}\n",
      "----\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n",
      "{'content': 'hi my name is jayanth', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '857fe669-21f7-4de4-9ac6-6fbe4b1f4c11'}\n",
      "----\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "{'content': 'Awesome, jayanth! üéØ What topic would you like to practice? (e.g. Python, JavaScript, SQL, React, Java, C++, etc.)', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': '73045422-96f4-46c2-881f-231b55fda5ef', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}\n",
      "----\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n",
      "{'content': 'sql please', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '7c8b478e-3c3f-4c52-952f-548533efcb26'}\n",
      "----\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "{'content': 'Great choice, jayanth! SQL is super useful.\\n\\nTo kick things off, in your own words, what would you say SQL is primarily used for? No need for a perfect definition, just your understanding!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': '2779dba1-7405-4b76-ab46-25827c80128c', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}\n",
      "----\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n",
      "{'content': 'sql is an language to create, manage the databse systems , it has DML, DQL,TCL, DRL', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '2bafc44b-380d-4fc1-97ed-3ed05ffd832b'}\n",
      "----\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "{'content': \"That's a great start! You're absolutely right that SQL is used for creating and managing databases. You've correctly identified DML, DQL, and TCL. We also have DDL for defining the database structure and DCL for controlling access, and DRL is often grouped under DQL.\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': '1dacc775-bb45-4c13-8669-fc64e298654d', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}\n",
      "----\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "{'content': \"Excellent, jayanth! You've got a good handle on the different categories of SQL commands.\\n\\nLet's move on to one of the most common commands. What do you think the `SELECT` statement is used for in SQL?\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'c61dc93b-44d2-4049-b6c3-b6dbcc9bd567', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}\n",
      "----\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n",
      "{'content': 'SELECT is used to retrive data from the table', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'f6ed9d22-8d9e-4825-8f80-9b23a7570bcd'}\n",
      "----\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "{'content': \"That's absolutely right! You've got a great understanding of what SELECT does. Keep up the fantastic work!\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': '02edfddc-31a3-4bb6-9985-21625fe1d16d', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}\n",
      "----\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "{'content': \"Excellent, jayanth! You're doing great.\\n\\nYou mentioned `SELECT` is used to retrieve data. When you're writing a `SELECT` statement, you also need to tell SQL *which* table to get the data from. Which keyword do we use for that?\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'e8cb6771-cb8a-4191-9bf3-b358bed3a10b', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}\n",
      "----\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n",
      "{'content': 'we use SELECT column_name from TABLE_NAME', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'c8f264f7-ce2a-4dde-b2f7-56ac92ede001'}\n",
      "----\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "{'content': \"That's absolutely right! You've got the basic SELECT statement down perfectly for picking out a specific column. Great job!\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': '4a676146-9598-40c6-a646-2cd06bbabf6c', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}\n",
      "----\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "{'content': \"Great job jayanth! üéâ That was a solid practice session on sql. Keep learning and you'll do amazing. Good luck! üöÄ\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': '99acbcc6-fb24-49f1-a8e3-0cacfd8c4fd5', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for msg in state.values.get(\"messages\", []):\n",
    "    print(type(msg))\n",
    "    print(msg.model_dump())\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
